{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a327cb",
   "metadata": {},
   "source": [
    "\n",
    "# HugeCTR Model Updating with Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc81c",
   "metadata": {},
   "source": [
    "### 1.1 Generate new model folders\n",
    "For example, the previous wdl model_version is 1 and the new wdl model_verison is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8da341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/wdl_infer\"\n",
    "model_folder  = os.path.join(BASE_DIR, \"model\")\n",
    "wdl_model_repo= os.path.join(model_folder, \"wdl\")\n",
    "wdl_version =os.path.join(wdl_model_repo, \"2\")\n",
    "\n",
    "if os.path.isdir(model_folder):\n",
    "    shutil.rmtree(model_folder)\n",
    "os.makedirs(model_folder)\n",
    "\n",
    "if os.path.isdir(wdl_model_repo):\n",
    "    shutil.rmtree(wdl_model_repo)\n",
    "os.makedirs(wdl_model_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72680473",
   "metadata": {},
   "source": [
    "### 1.2 Copy WDL model files and configuration to model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8395d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5840\n",
      "-rw-r--r-- 1 root root    3628 Dec  3 03:36 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Dec  3 03:36 wdl_0_sparse_model\n",
      "drwxr-xr-x 2 root root    4096 Dec  3 03:36 wdl_1_sparse_model\n",
      "-rw-r--r-- 1 root root 5963780 Dec  3 03:36 wdl_dense_0.model\n"
     ]
    }
   ],
   "source": [
    "!cp -r wdl_0_sparse_model $wdl_version/\n",
    "!cp -r wdl_1_sparse_model $wdl_version/\n",
    "!cp  wdl_dense_0.model $wdl_version/\n",
    "!cp wdl.json $wdl_version/\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12406f",
   "metadata": {},
   "source": [
    "### 1.3 Modify the Triton configuration for updating WDL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a4b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /wdl_infer/model/wdl/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_model_repo/config.pbtxt\n",
    "name: \"wdl\"\n",
    "backend: \"hugectr\"\n",
    "max_batch_size:64,\n",
    "input [\n",
    "   {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"ROWINDEX\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "version_policy:{\n",
    "    specific:{versions:2}\n",
    "}\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "\n",
    "parameters [\n",
    "  {\n",
    "  key: \"config\"\n",
    "  value: { string_value: \"/wdl_infer/model/wdl/2/wdl.json\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucache\"\n",
    "  value: { string_value: \"true\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"freeze_sparse\"\n",
    "  value: { string_value: \"false\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"hit_rate_threshold\"\n",
    "  value: { string_value: \"0.8\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"refresh_interval\"\n",
    "  value: { string_value: \"20\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"refresh_delay\"\n",
    "  value: { string_value: \"0.0\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucacheper\"\n",
    "  value: { string_value: \"0.5\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"label_dim\"\n",
    "  value: { string_value: \"1\" }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7384a6",
   "metadata": {},
   "source": [
    "### 1.4 Modifying the HugeCTR Backend parameter server configuration for updaing WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0fb4a75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /wdl_infer/model/ps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /wdl_infer/model/ps.json\n",
    "{\n",
    "    \"supportlonglong\":true,\n",
    "    \"volatile_db\": {\n",
    "        \"type\": \"redis_cluster\",\n",
    "        \"address\": \"127.0.0.1:7000,127.0.0.1:7001,127.0.0.1:7002\",\n",
    "        \"user_name\": \"default\",\n",
    "        \"password\": \"\",\n",
    "        \"num_partitions\": 8,\n",
    "        \"max_get_batch_size\": 100000,\n",
    "        \"max_set_batch_size\": 100000,\n",
    "        \"overflow_policy\": \"evict_oldest\",\n",
    "        \"overflow_margin\": 10000000,\n",
    "        \"overflow_resolution_target\": 0.8,\n",
    "        \"initial_cache_rate\": 1.0,\n",
    "        \"update_filters\": [ \".+\" ]\n",
    "    },\n",
    "    \"persistent_db\": {\n",
    "        \"type\": \"rocksdb\",\n",
    "        \"path\": \"/wdl_infer/rocksdb\",\n",
    "        \"num_threads\": 16,\n",
    "        \"read_only\": false,\n",
    "        \"max_get_batch_size\": 1,\n",
    "        \"max_set_batch_size\": 10000,\n",
    "        \"update_filters\": [ \"^hps_.+$\" ]\n",
    "    },\n",
    "    \"update_source\": {\n",
    "        \"type\": \"kafka\",\n",
    "        \"brokers\": \"10.23.137.25:9093\",\n",
    "        \"receive_buffer_size\": 262144,\n",
    "        \"poll_timeout_ms\": 500,\n",
    "        \"max_batch_size\": 8192,\n",
    "        \"failure_backoff_ms\": 50,\n",
    "        \"max_commit_interval\": 32\n",
    "    },\n",
    "    \"models\":[\n",
    "        {\n",
    "            \"model\":\"wdl\",\n",
    "            \"sparse_files\":[\"/wdl_infer/model/wdl/2/wdl_0_sparse_model\", \"/wdl_infer/model/wdl/1/wdl_1_sparse_model\"],\n",
    "            \"dense_file\":\"/wdl_infer/model/wdl/2/wdl_dense_0.model\",\n",
    "            \"network_file\":\"/wdl_infer/model/wdl/2/wdl.json\",\n",
    "            \"num_of_worker_buffer_in_pool\": 1,\n",
    "            \"num_of_refresher_buffer_in_pool\": 1,\n",
    "            \"cache_refresh_percentage_per_iteration\": 0.2,\n",
    "            \"deployed_device_list\":[0],\n",
    "            \"max_batch_size\":64,\n",
    "            \"default_value_for_each_table\":[0.0,0.0],\n",
    "            \"hit_rate_threshold\":0.9,\n",
    "            \"gpucacheper\":0.5,\n",
    "            \"gpucache\":true,\n",
    "            \"maxnum_des_feature_per_sample\": 13,\n",
    "\t\t\t\"maxnum_catfeature_query_per_table_per_sample\" : [2,26],\n",
    "\t\t\t\"embedding_vecsize_per_table\" : [1,15],\n",
    "\t\t\t\"slot_num\":28\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed729b3",
   "metadata": {},
   "source": [
    "### 2.1 Inference using Triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be36454",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile triton_infer.py\n",
    "\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.http  as httpclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "model_name = 'wdl'\n",
    "CATEGORICAL_COLUMNS=[\"C1_C2\",\"C3_C4\"] + [\"C\" + str(x) for x in range(1, 27)]\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 14)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "test_df=pd.read_csv(\"infer_data.csv\",sep=',')\n",
    "\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    dense_features = np.array([list(test_df[CONTINUOUS_COLUMNS].values.flatten())],dtype='float32')\n",
    "    embedding_columns = np.array([list((test_df[CATEGORICAL_COLUMNS]).values.flatten())],dtype='int64')\n",
    "    row_ptrs = np.array([list(range(0,11, 2)) + list(range(0,131))], dtype='int32')\n",
    "    \n",
    "    inputs = [\n",
    "        httpclient.InferInput(\"DES\", dense_features.shape,\n",
    "                              np_to_triton_dtype(dense_features.dtype)),\n",
    "        httpclient.InferInput(\"CATCOLUMN\", embedding_columns.shape,\n",
    "                              np_to_triton_dtype(embedding_columns.dtype)),\n",
    "        httpclient.InferInput(\"ROWINDEX\", row_ptrs.shape,\n",
    "                              np_to_triton_dtype(row_ptrs.dtype)),\n",
    "\n",
    "    ]\n",
    "\n",
    "    inputs[0].set_data_from_numpy(dense_features)\n",
    "    inputs[1].set_data_from_numpy(embedding_columns)\n",
    "    inputs[2].set_data_from_numpy(row_ptrs)\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    response = client.infer(model_name,\n",
    "                            inputs,\n",
    "                            request_id=str(1),\n",
    "                            outputs=outputs)\n",
    "\n",
    "    result = response.get_response()\n",
    "    print(result)\n",
    "    print(\"Prediction Result:\")\n",
    "    print(response.as_numpy(\"OUTPUT0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62848c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'model_name': 'wdl', 'model_version': '1', 'parameters': {'NumSample': 5, 'DeviceID': 0}, 'outputs': [{'name': 'OUTPUT0', 'datatype': 'FP32', 'shape': [5], 'parameters': {'binary_data_size': 20}}]}\n",
      "Prediction Result:\n",
      "[0.01366859 0.00814866 0.06785329 0.00727612 0.01993068]\n"
     ]
    }
   ],
   "source": [
    "!python3 triton_infer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab5ac8",
   "metadata": {},
   "source": [
    "\n",
    "# HugeCTR Model Replacing with Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e489b0",
   "metadata": {},
   "source": [
    "### 1.1 Generate new model folders\n",
    "For example, we replace old wdl model with new dlrm model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some data folder to store the model related files\n",
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/dlrm_infer\"\n",
    "model_folder  = os.path.join(BASE_DIR, \"model\")\n",
    "dlrm_model_repo= os.path.join(model_folder, \"dlrm\")\n",
    "dlrm_version =os.path.join(dlrm_model_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(model_folder):\n",
    "    shutil.rmtree(model_folder)\n",
    "os.makedirs(model_folder)\n",
    "\n",
    "if os.path.isdir(dlrm_model_repo):\n",
    "    shutil.rmtree(dlrm_model_repo)\n",
    "os.makedirs(dlrm_model_repo)\n",
    "\n",
    "if os.path.isdir(dlrm_version):\n",
    "    shutil.rmtree(dlrm_version)\n",
    "os.makedirs(dlrm_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d21f37",
   "metadata": {},
   "source": [
    "### 1.2 Copy DLRM model files to model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r /dlrm_train/dlrm0_sparse_20000.model $dlrm_version/\n",
    "! cp /dlrm_train/dlrm_dense_20000.model $dlrm_version/\n",
    "! cp /dlrm_train/dlrm.json $dlrm_version/\n",
    "!ls -l $dlrm_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a44f7e",
   "metadata": {},
   "source": [
    "### 1.3 Generate the Triton configuration for deploying DLRM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $dlrm_model_repo/config.pbtxt\n",
    "name: \"dlrm\"\n",
    "backend: \"hugectr\"\n",
    "max_batch_size:64,\n",
    "input [\n",
    "   {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"ROWINDEX\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "\n",
    "version_policy: {\n",
    "        specific:{versions: 1}\n",
    "}\n",
    "\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "\n",
    "parameters [\n",
    "  {\n",
    "  key: \"config\"\n",
    "  value: { string_value: \"/dlrm_infer/model/dlrm/1/dlrm.json\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucache\"\n",
    "  value: { string_value: \"true\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"freeze_sparse\"\n",
    "  value: { string_value: \"false\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucacheper\"\n",
    "  value: { string_value: \"0.5\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"label_dim\"\n",
    "  value: { string_value: \"1\" }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89785e48",
   "metadata": {},
   "source": [
    "### 1.4 Generate the Hugectr Backend parameter server configuration for deploying dlrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $model_folder/ps.json\n",
    "{\n",
    "    \"supportlonglong\":true,\n",
    "    \"models\":[\n",
    "        {\n",
    "            \"model\":\"dlrm\",\n",
    "            \"sparse_files\":[\"/dlrm_infer/model/dlrm/1/dlrm0_sparse_20000.model\"],\n",
    "            \"dense_file\":\"/dlrm_infer/model/dlrm/1/dlrm_dense_20000.model\",\n",
    "            \"network_file\":\"/dlrm_infer/model/dlrm/1/dlrm.json\",\n",
    "            \"num_of_worker_buffer_in_pool\": 4,\n",
    "            \"num_of_refresher_buffer_in_pool\":1,\n",
    "            \"deployed_device_list\":[0],\n",
    "            \"max_batch_size\":64,\n",
    "            \"default_value_for_each_table\":[0.0],\n",
    "            \"hit_rate_threshold\":\"0.9\",\n",
    "            \"gpucacheper\":0.5,\n",
    "            \"gpucache\":true,\n",
    "            \"cache_refresh_percentage_per_iteration\":0.2,\n",
    "            \"maxnum_des_feature_per_sample\": 13,\n",
    "            \"maxnum_catfeature_query_per_table_per_sample\":[26],\n",
    "            \"embedding_vecsize_per_table\":[128],\n",
    "            \"slot_num\":26\n",
    "        }\n",
    "    ]  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a81619",
   "metadata": {},
   "source": [
    "### 1.5 Unload wdl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d043e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    client.unload_model(\"wdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451075f",
   "metadata": {},
   "source": [
    "### 1.6 Load dlrm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67581ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    client.load_model(\"dlrm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
