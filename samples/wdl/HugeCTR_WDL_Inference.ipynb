{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf99cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b57aa2",
   "metadata": {},
   "source": [
    "# 1.Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014fbdd",
   "metadata": {},
   "source": [
    "In this notebook, we want to provide a tutorial about how to make inference using HugeCTR trained WDL model. And we can collect the inference benchmark by Triton performance analyzer tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5782175",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. Generate the WDL deployment Configuration\n",
    "3. Load Models on the Triton Server\n",
    "4. Prepare Inference Input Data \n",
    "5. Inference Benchmarm by Triton Performance Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1501b8",
   "metadata": {},
   "source": [
    "# 2. Generate the WDL Deployment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6522f8f4",
   "metadata": {},
   "source": [
    "## 2.1 Generate related model folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cf34f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some data folder to store the model related files\n",
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/wdl_infer\"\n",
    "model_folder  = os.path.join(BASE_DIR, \"model\")\n",
    "wdl_model_repo= os.path.join(model_folder, \"wdl\")\n",
    "wdl_version =os.path.join(wdl_model_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(model_folder):\n",
    "    shutil.rmtree(model_folder)\n",
    "os.makedirs(model_folder)\n",
    "\n",
    "if os.path.isdir(wdl_model_repo):\n",
    "    shutil.rmtree(wdl_model_repo)\n",
    "os.makedirs(wdl_model_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca970c",
   "metadata": {},
   "source": [
    "## 2.2 Copy WDL model files and configuration to model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbfdb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /wdl_train/wdl0_sparse_20000.model $wdl_version/\n",
    "!cp -r /wdl_train/wdl1_sparse_20000.model $wdl_version/\n",
    "!cp  /wdl_train/wdl_dense_20000.model $wdl_version/\n",
    "!cp /wdl_train/wdl.json $wdl_version/\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c606f",
   "metadata": {},
   "source": [
    "## 2.3 Generate the Triton configuration for deploying WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eebe3ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/model/wdl/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_model_repo/config.pbtxt\n",
    "name: \"wdl\"\n",
    "backend: \"hugectr\"\n",
    "max_batch_size:64,\n",
    "input [\n",
    "   {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"ROWINDEX\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "\n",
    "parameters [\n",
    "  {\n",
    "  key: \"config\"\n",
    "  value: { string_value: \"/wdl_infer/model/wdl/1/wdl.json\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucache\"\n",
    "  value: { string_value: \"true\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"hit_rate_threshold\"\n",
    "  value: { string_value: \"0.8\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucacheper\"\n",
    "  value: { string_value: \"0.5\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"label_dim\"\n",
    "  value: { string_value: \"1\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"slots\"\n",
    "  value: { string_value: \"28\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"cat_feature_num\"\n",
    "  value: { string_value: \"28\" }\n",
    "  },\n",
    " {\n",
    "  key: \"des_feature_num\"\n",
    "  value: { string_value: \"13\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"max_nnz\"\n",
    "  value: { string_value: \"2\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"embedding_vector_size\"\n",
    "  value: { string_value: \"128\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"embeddingkey_long_type\"\n",
    "  value: { string_value: \"true\" }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3ac4b",
   "metadata": {},
   "source": [
    "## 2.4 Generate the Hugectr Backend parameter server configuration for deploying wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01a3e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/model/ps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /wdl_infer/model/ps.json\n",
    "{\n",
    "    \"supportlonglong\":true,\n",
    "    \"models\":[\n",
    "        {\n",
    "            \"model\":\"wdl\",\n",
    "            \"sparse_files\":[\"/wdl_infer/model/wdl/1/wdl0_sparse_20000.model\", \"/wdl_infer/model/wdl/1/wdl1_sparse_20000.model\"],\n",
    "            \"dense_file\":\"/wdl_infer/model/wdl/1/wdl_dense_20000.model\",\n",
    "            \"network_file\":\"/wdl_infer/model/wdl/1/wdl.json\",\n",
    "            \"num_of_worker_buffer_in_pool\": \"4\",\n",
    "            \"num_of_refresher_buffer_in_pool\":\"1\",\n",
    "            \"deployed_device_list\":[\"0\"],\n",
    "            \"max_batch_size\":\"64\",\n",
    "            \"default_value_for_each_table\":[\"0.0\",\"0.0\"],\n",
    "            \"hit_rate_threshold\":\"0.9\",\n",
    "            \"gpucacheper\":\"0.5\",\n",
    "            \"gpucache\":\"true\",\n",
    "            \"cache_refresh_percentage_per_iteration\":0.2\n",
    "        }\n",
    "    ]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3699d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1\n",
      "drwxr-xr-x 4 root root 4096 Nov 29 06:13 1\n",
      "-rw-r--r-- 1 root root 1174 Nov 29 06:13 config.pbtxt\n",
      "total 5858\n",
      "-rw-r--r-- 1 root root    3731 Nov 29 06:13 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Nov 29 06:13 wdl0_sparse_20000.model\n",
      "drwxr-xr-x 2 root root    4096 Nov 29 06:13 wdl1_sparse_20000.model\n",
      "-rw-r--r-- 1 root root 5963780 Nov 29 06:13 wdl_dense_20000.model\n"
     ]
    }
   ],
   "source": [
    "!ls  -l $wdl_model_repo\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70c464",
   "metadata": {},
   "source": [
    "# 3.Deploy WDL on Triton Server "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03270f87",
   "metadata": {},
   "source": [
    "At this stage, you should have already launched the Triton Inference Server with the following command:\n",
    "\n",
    "In this tutorial, we will deploy the Wide&Deep to a single A100(32GB)\n",
    "\n",
    "docker run --gpus=all -it -v /wdl_infer/:/wdl_infer -v /wdl_train/:/wdl_train --net=host nvcr.io/nvidia/merlin/merlin-inference:22.05 /bin/bash\n",
    "After you enter into the container you can launch triton server with the command below:\n",
    "\n",
    "tritonserver --model-repository=/wdl_infer/model/ --load-model=wdl \n",
    "    --model-control-mode=explicit \n",
    "    --backend-directory=/usr/local/hugectr/backends \n",
    "    --backend-config=hugectr,ps=/wdl_infer/model/ps.json\n",
    "\n",
    "Note: The model-repository path is /wdl_infer/model/. \n",
    "\n",
    "The path for the parameter server configuration file is /wdl_infer/model/ps.json."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c85e79",
   "metadata": {},
   "source": [
    "### 3.1 Check Triton server status if deploy Wide&Deep model successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ea4d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:8000...\r\n",
      "* TCP_NODELAY set\r\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\r\n",
      "> GET /v2/health/ready HTTP/1.1\r\n",
      "\r\n",
      "> Host: localhost:8000\r\n",
      "\r\n",
      "> User-Agent: curl/7.68.0\r\n",
      "\r\n",
      "> Accept: */*\r\n",
      "\r\n",
      "> \r\n",
      "\r\n",
      "* Mark bundle as not supporting multiuse\r\n",
      "< HTTP/1.1 200 OK\r\n",
      "\r\n",
      "< Content-Length: 0\r\n",
      "\r\n",
      "< Content-Type: text/plain\r\n",
      "\r\n",
      "< \r\n",
      "\r\n",
      "* Connection #0 to host localhost left intact\r\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17182660",
   "metadata": {},
   "source": [
    "# 4. Prepare Inference Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bdab8",
   "metadata": {},
   "source": [
    "### 4.1 Read validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3c4b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14542626\r\n",
      "-rw-r--r-- 1 root root          34 Nov 29 05:27 _file_list.txt\r\n",
      "-rw-r--r-- 1 root root     8554464 Nov 29 05:27 _hugectr.keyset\r\n",
      "-rw-r--r-- 1 root root      471772 Nov 29 05:27 _metadata\r\n",
      "-rw-r--r-- 1 root root        1510 Nov 29 05:27 _metadata.json\r\n",
      "-rw-r--r-- 1 root root  3332773998 Nov 29 05:27 part_0.parquet\r\n",
      "-rw-r--r-- 1 root root       21459 Nov 29 05:27 schema.pbtxt\r\n",
      "drwxr-xr-x 2 root root        4096 Nov 29 05:26 temp-parquet-after-conversion\r\n",
      "-rw-r--r-- 1 root root 11549710546 Nov 29 03:50 train.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /wdl_train/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e59afcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"/wdl_train/train/part_0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab8758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.031058</td>\n",
       "      <td>0.350474</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>-0.091675</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.068484</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.224423</td>\n",
       "      <td>-0.760031</td>\n",
       "      <td>1.386036</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.217361</td>\n",
       "      <td>-0.594327</td>\n",
       "      <td>-0.157301</td>\n",
       "      <td>-0.147269</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.279201</td>\n",
       "      <td>-0.760031</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075348</td>\n",
       "      <td>2.096091</td>\n",
       "      <td>0.156849</td>\n",
       "      <td>-0.157301</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.281810</td>\n",
       "      <td>0.107562</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>179</td>\n",
       "      <td>133</td>\n",
       "      <td>145</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.048792</td>\n",
       "      <td>0.338248</td>\n",
       "      <td>-0.379705</td>\n",
       "      <td>-0.157301</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.101824</td>\n",
       "      <td>-0.615432</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4756</td>\n",
       "      <td>236</td>\n",
       "      <td>4090</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.426563</td>\n",
       "      <td>-0.594327</td>\n",
       "      <td>-0.157301</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>2.094522</td>\n",
       "      <td>-0.760031</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1299</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         I1        I2        I3        I4        I5        I6        I7  \\\n",
       "0 -0.031058  0.350474  0.264160 -0.091675  0.023207  0.068484 -0.064249   \n",
       "1 -0.059432 -0.217361 -0.594327 -0.157301 -0.147269 -0.206385 -0.064249   \n",
       "2  0.075348  2.096091  0.156849 -0.157301 -0.224758 -0.206385 -0.064249   \n",
       "3 -0.048792  0.338248 -0.379705 -0.157301 -0.224758 -0.206385 -0.064249   \n",
       "4 -0.059432 -0.426563 -0.594327 -0.157301 -0.224758 -0.206385 -0.064249   \n",
       "\n",
       "         I8        I9       I10  ...  C18  C19   C20  C21   C22  C23   C24  \\\n",
       "0 -0.224423 -0.760031  1.386036  ...    1    2     1    1     1    1    25   \n",
       "1 -0.279201 -0.760031 -0.470383  ...    2    2     1    1     1    1   210   \n",
       "2 -0.281810  0.107562 -0.470383  ...   17    3   115  179   133  145    26   \n",
       "3 -0.101824 -0.615432 -0.470383  ...    3    1  4756  236  4090    0    19   \n",
       "4  2.094522 -0.760031 -0.470383  ...    1    7     8   11     8    0  1299   \n",
       "\n",
       "   C25  C26  label  \n",
       "0    1    2    0.0  \n",
       "1    1    2    0.0  \n",
       "2    2    3    0.0  \n",
       "3    1    1    0.0  \n",
       "4    8    3    0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23881de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10).to_csv('/wdl_infer/infer_test.csv', sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd9e7f",
   "metadata": {},
   "source": [
    "## 4.2 Follow the Triton requirements to generate inference requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c28257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/wdl2predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /wdl_infer/wdl2predict.py\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.http  as httpclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "model_name = 'wdl'\n",
    "CATEGORICAL_COLUMNS=[\"C1_C2\",\"C3_C4\"]+[\"C\" + str(x) for x in range(1, 27)]\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 14)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "emb_size_array = [278018, 415262,249058, 19561, 14212, 6890, 18592, 4, 6356, 1254, 52, 226170, 80508, 72308, 11, 2169, 7597, 61, 4, 923, 15, 249619, 168974, 243480, 68212, 9169, 75, 34]\n",
    "shift = np.insert(np.cumsum(emb_size_array), 0, 0)[:-1]\n",
    "test_df=pd.read_csv(\"/wdl_infer/infer_test.csv\",sep=',')\n",
    "\n",
    "\n",
    "\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    dense_features = np.array([list(test_df[CONTINUOUS_COLUMNS].values.flatten())],dtype='float32')\n",
    "    embedding_columns = np.array([list((test_df[CATEGORICAL_COLUMNS]+shift).values.flatten())],dtype='int64')\n",
    "    row_ptrs = np.array([list(range(0,21))+list(range(0,261))],dtype='int32')\n",
    "    \n",
    "    inputs = [\n",
    "        httpclient.InferInput(\"DES\", dense_features.shape,\n",
    "                              np_to_triton_dtype(dense_features.dtype)),\n",
    "        httpclient.InferInput(\"CATCOLUMN\", embedding_columns.shape,\n",
    "                              np_to_triton_dtype(embedding_columns.dtype)),\n",
    "        httpclient.InferInput(\"ROWINDEX\", row_ptrs.shape,\n",
    "                              np_to_triton_dtype(row_ptrs.dtype)),\n",
    "\n",
    "    ]\n",
    "\n",
    "    inputs[0].set_data_from_numpy(dense_features)\n",
    "    inputs[1].set_data_from_numpy(embedding_columns)\n",
    "    inputs[2].set_data_from_numpy(row_ptrs)\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    response = client.infer(model_name,\n",
    "                            inputs,\n",
    "                            request_id=str(1),\n",
    "                            outputs=outputs)\n",
    "\n",
    "    result = response.get_response()\n",
    "    print(result)\n",
    "    print(\"Prediction Result:\")\n",
    "    print(response.as_numpy(\"OUTPUT0\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ace140",
   "metadata": {},
   "source": [
    "## 4.3 Send requests to Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "971b061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'model_name': 'wdl', 'model_version': '1', 'parameters': {'NumSample': 10, 'DeviceID': 0}, 'outputs': [{'name': 'OUTPUT0', 'datatype': 'FP32', 'shape': [10], 'parameters': {'binary_data_size': 40}}]}\r\n",
      "Prediction Result:\r\n",
      "[0.03392845 0.02259001 0.00255735 0.00028795 0.00226125 0.02724345\r\n",
      " 0.00389859 0.00180469 0.03567842 0.00802261]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./wdl2predict.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
