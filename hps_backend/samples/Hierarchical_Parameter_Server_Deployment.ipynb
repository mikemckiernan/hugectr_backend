{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f002d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4ae0b",
   "metadata": {},
   "source": [
    "# 1.Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22707757",
   "metadata": {},
   "source": [
    "In this notebook, we want to provide a tutorial about how to use the Hierarchical Parameter Server(HPS) backend to look up the embedding keys for inference service, here we still use the two embedding tables of the wdl model trained by HugeCTR as the embedding file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2392df",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. Generate the HPS deployment Configuration\n",
    "3. Load Embedding tables on the Triton Server\n",
    "4. Prepare Embedding keys as Input Data for looking up\n",
    "5. Looking up embedding keys from HPS Backend Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc0f17",
   "metadata": {},
   "source": [
    "# 2. Generate the HPS Deployment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f78f7f",
   "metadata": {},
   "source": [
    "## 2.1 Generate  hps backend and embedding folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e9b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some data folder to store the model related files\n",
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/hps_infer\"\n",
    "embedding_folder  = os.path.join(BASE_DIR, \"embedding\")\n",
    "wdl_embedding_repo= os.path.join(embedding_folder, \"hps_wdl\")\n",
    "wdl_version =os.path.join(wdl_embedding_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(embedding_folder):\n",
    "    shutil.rmtree(embedding_folder)\n",
    "os.makedirs(embedding_folder)\n",
    "\n",
    "if os.path.isdir(wdl_embedding_repo):\n",
    "    shutil.rmtree(wdl_embedding_repo)\n",
    "os.makedirs(wdl_embedding_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d9d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5840\n",
      "-rwxr-xr-x 1 root root    3590 Jun 29 07:54 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:54 wdl0_sparse_20000.model\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:54 wdl1_sparse_20000.model\n",
      "-rw-r--r-- 1 root root 5963780 Jun 29 07:54 wdl_dense_20000.model\n"
     ]
    }
   ],
   "source": [
    "!cp -r /workspace/data/wdl_models/wdl0_sparse_20000.model $wdl_version/\n",
    "!cp -r /workspace/data/wdl_models/wdl1_sparse_20000.model $wdl_version/\n",
    "!cp /workspace/data/wdl_models/wdl_dense_20000.model $wdl_version/\n",
    "!cp /workspace/data/wdl_models/wdl.json $wdl_version/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c885a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/hps_infer/embedding/hps_wdl/1\u001b[00m\n",
      "├── \u001b[01;32mwdl.json\u001b[00m\n",
      "├── \u001b[01;34mwdl0_sparse_20000.model\u001b[00m\n",
      "│   ├── emb_vector\n",
      "│   ├── key\n",
      "│   ├── wdl0_sparse_20000.model.key\n",
      "│   └── wdl0_sparse_20000.model.vec\n",
      "├── \u001b[01;34mwdl1_sparse_20000.model\u001b[00m\n",
      "│   ├── emb_vector\n",
      "│   ├── key\n",
      "│   ├── wdl1_sparse_20000.model.key\n",
      "│   └── wdl1_sparse_20000.model.vec\n",
      "└── wdl_dense_20000.model\n",
      "\n",
      "2 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "!tree $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652a705",
   "metadata": {},
   "source": [
    "## 2.2 Copy embedding tables of wdl model to embedding repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e25ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 Apr  1 09:09 wdl0_sparse_2000.model\n",
      "drwxr-xr-x 2 root root 4096 Apr  1 09:09 wdl1_sparse_2000.model\n"
     ]
    }
   ],
   "source": [
    "!cp -r /wdl_train/wdl0_sparse_2000.model $wdl_version/\n",
    "!cp -r /wdl_train/wdl1_sparse_2000.model $wdl_version/\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99a23e",
   "metadata": {},
   "source": [
    "## 2.3 Generate the HPS configuration for deploying embedding tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352f61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /hps_infer/embedding/hps_wdl/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_embedding_repo/config.pbtxt\n",
    "name: \"hps_wdl\"\n",
    "backend: \"hps\"\n",
    "max_batch_size:1024,\n",
    "input [\n",
    "  {\n",
    "    name: \"KEYS\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"NUMKEYS\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "version_policy: {\n",
    "        specific:{versions: 1}\n",
    "},\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e917cd4",
   "metadata": {},
   "source": [
    "## 2.4 Configure hashmap for the localized embedding table storage\n",
    "In this case, we only use the local hashmap for demonstration. If you need to use distributed redis cluster and rocksdb for hierarchical embedded table storage, please refer to the detailed introduction [here](../docs/hierarchical_parameter_server.md#configuration), and add the corresponding configuration to the following hps.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b02e9",
   "metadata": {},
   "source": [
    "## 2.5 Generate the HPS  configuration for deploying embedding tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c2d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hps_infer/embedding/hps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hps_infer/embedding/hps.json\n",
    "{\n",
    "    \"supportlonglong\": true,\n",
    "    \"volatile_db\": {\n",
    "        \"type\": \"hash_map\",\n",
    "        \"user_name\": \"default\",\n",
    "        \"num_partitions\": 8,\n",
    "        \"max_get_batch_size\": 100000,\n",
    "        \"max_set_batch_size\": 100000,\n",
    "        \"overflow_policy\": \"evict_oldest\",\n",
    "        \"overflow_margin\": 10000000,\n",
    "        \"overflow_resolution_target\": 0.8,\n",
    "        \"initial_cache_rate\": 1.0\n",
    "    },\n",
    "    \"persistent_db\": {\n",
    "        \"type\": \"disabled\"\n",
    "    },\n",
    "    \"models\": [{\n",
    "        \"model\": \"hps_wdl\",\n",
    "        \"sparse_files\": [\"/hps_infer/embedding/hps_wdl/1/wdl0_sparse_20000.model\", \"/hps_infer/embedding/hps_wdl/1/wdl1_sparse_20000.model\"],\n",
    "        \"num_of_worker_buffer_in_pool\": 3,\n",
    "        \"embedding_table_names\":[\"embedding_table1\",\"embedding_table2\"],\n",
    "        \"embedding_vecsize_per_table\":[1,16],\n",
    "        \"maxnum_catfeature_query_per_table_per_sample\":[2,26],\n",
    "        \"default_value_for_each_table\":[0.0,0.0],\n",
    "        \"deployed_device_list\":[0],\n",
    "        \"max_batch_size\":1024,\n",
    "        \"cache_refresh_percentage_per_iteration\":0.2,\n",
    "        \"hit_rate_threshold\":0.9,\n",
    "        \"gpucacheper\":0.5,\n",
    "        \"gpucache\":true\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db97930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 4 root root 4096 Jun 29 07:54 1\n",
      "-rw-r--r-- 1 root root  408 Jun 29 08:02 config.pbtxt\n",
      "total 5840\n",
      "-rwxr-xr-x 1 root root    3590 Jun 29 07:54 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:54 wdl0_sparse_20000.model\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:54 wdl1_sparse_20000.model\n",
      "-rw-r--r-- 1 root root 5963780 Jun 29 07:54 wdl_dense_20000.model\n"
     ]
    }
   ],
   "source": [
    "!ls -l $wdl_embedding_repo\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a47dc",
   "metadata": {},
   "source": [
    "# 3.Deploy HPS Backend on Triton Server "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8db3e",
   "metadata": {},
   "source": [
    "At this stage, you should have already launched the Triton Inference Server with the following command:\n",
    "\n",
    "In this tutorial, we will deploy the Wide&Deep to a single A100(32GB),\n",
    "\n",
    "Note: `Since Background processes not supported by Jupyter, please launch the Triton Server according to the following command independently in the background.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tritonserver --model-repository=/hps_infer/embedding/ --load-model=hps_wdl \\\n",
    "    --model-control-mode=explicit \\\n",
    "    --backend-directory=/usr/local/hugectr/backends \\\n",
    "    --backend-config=hps,ps=/hps_infer/embedding/hps.json\n",
    "!tritonserver --model-repository=/hps_infer/embedding/ --load-model=hps_wdl --model-control-mode=explicit --backend-directory=/usr/local/hugectr/backends --backend-config=hps,ps=/hps_infer/embedding/hps.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b271b13",
   "metadata": {},
   "source": [
    "### 3.1 Check Triton server status if deploy two embedding tables successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3211a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:8000...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\n",
      "> GET /v2/health/ready HTTP/1.1\n",
      "> Host: localhost:8000\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Length: 0\n",
      "< Content-Type: text/plain\n",
      "< \n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4467413",
   "metadata": {},
   "source": [
    "# 4. Prepare Inference Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8892d",
   "metadata": {},
   "source": [
    "### 4.1 Read validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8903c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 645762\n",
      "-rw-r--r-- 1 root root        32 Nov 29 05:27 _file_list.txt\n",
      "-rw-r--r-- 1 root root   8554464 Nov 29 05:27 _hugectr.keyset\n",
      "-rw-r--r-- 1 root root     22726 Nov 29 05:27 _metadata\n",
      "-rw-r--r-- 1 root root      1509 Nov 29 05:27 _metadata.json\n",
      "-rw-r--r-- 1 root root 142825257 Nov 29 05:27 part_0.parquet\n",
      "-rw-r--r-- 1 root root     21459 Nov 29 05:27 schema.pbtxt\n",
      "drwxr-xr-x 2 root root      4096 Nov 29 05:26 temp-parquet-after-conversion\n",
      "-rw-r--r-- 1 root root 509766965 Nov 29 03:50 test.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l /wdl_train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a06239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"/wdl_train/val/part_0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e23171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055886</td>\n",
       "      <td>-0.548824</td>\n",
       "      <td>-0.272394</td>\n",
       "      <td>-0.157301</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>0.096421</td>\n",
       "      <td>-0.543133</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3856</td>\n",
       "      <td>4891</td>\n",
       "      <td>4119</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.380376</td>\n",
       "      <td>-0.272394</td>\n",
       "      <td>5.629719</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.279201</td>\n",
       "      <td>-0.253935</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.539315</td>\n",
       "      <td>-0.594327</td>\n",
       "      <td>-0.142386</td>\n",
       "      <td>-0.193763</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.023569</td>\n",
       "      <td>-0.687732</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2439</td>\n",
       "      <td>41980</td>\n",
       "      <td>349</td>\n",
       "      <td>3549</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.463242</td>\n",
       "      <td>-0.594327</td>\n",
       "      <td>-0.097641</td>\n",
       "      <td>-0.209261</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.219206</td>\n",
       "      <td>-0.687732</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4024</td>\n",
       "      <td>3677</td>\n",
       "      <td>4287</td>\n",
       "      <td>565</td>\n",
       "      <td>306</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022145</td>\n",
       "      <td>-0.509429</td>\n",
       "      <td>-0.379705</td>\n",
       "      <td>-0.151335</td>\n",
       "      <td>-0.162767</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.281810</td>\n",
       "      <td>-0.470833</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>40847</td>\n",
       "      <td>3862</td>\n",
       "      <td>41562</td>\n",
       "      <td>1066</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         I1        I2        I3        I4        I5        I6        I7  \\\n",
       "0 -0.055886 -0.548824 -0.272394 -0.157301 -0.224758 -0.206385 -0.064249   \n",
       "1 -0.059432 -0.380376 -0.272394  5.629719 -0.224758 -0.206385 -0.064249   \n",
       "2 -0.059432 -0.539315 -0.594327 -0.142386 -0.193763 -0.206385 -0.064249   \n",
       "3 -0.059432 -0.463242 -0.594327 -0.097641 -0.209261 -0.206385 -0.064249   \n",
       "4  0.022145 -0.509429 -0.379705 -0.151335 -0.162767 -0.206385 -0.064249   \n",
       "\n",
       "         I8        I9       I10  ...  C18  C19    C20   C21    C22   C23  \\\n",
       "0  0.096421 -0.543133 -0.470383  ...    1    1   3856  4891   4119   143   \n",
       "1 -0.279201 -0.253935 -0.470383  ...    2    1      2     2      2     0   \n",
       "2 -0.023569 -0.687732 -0.470383  ...    1    1      0  2439  41980   349   \n",
       "3 -0.219206 -0.687732 -0.470383  ...    1    1   4024  3677   4287   565   \n",
       "4 -0.281810 -0.470833 -0.470383  ...    2    3  40847  3862  41562  1066   \n",
       "\n",
       "    C24  C25  C26  label  \n",
       "0    50    1    1    0.0  \n",
       "1   327    2    1    0.0  \n",
       "2  3549    6    1    1.0  \n",
       "3   306    4    1    0.0  \n",
       "4   132    2    1    0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cec3bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10).to_csv('/hps_infer/infer_test.csv', sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7fc71",
   "metadata": {},
   "source": [
    "## 4.2 Follow the Triton requirements to generate inference requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54de3154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hps_infer/hps2predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/hps_infer/hps2predict.py'\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.http  as httpclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "model_name = 'hps_wdl'\n",
    "batch_szie = 10\n",
    "emb1 = [\"C1_C2\",\"C3_C4\"]\n",
    "emb2 = [\"C\" + str(x) for x in range(1, 27)]\n",
    "CATEGORICAL_COLUMNS= emb1 + emb2\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 14)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "#This is the bias（offset）added the preprocessed training data, \n",
    "#which is added to inference data ensure that the embedded key of inference and training are in the same range, \n",
    "#and have nothing to do with the lookup logic of HPS\n",
    "emb_size_array = [278018, 415262,249058, 19561, 14212, 6890, 18592, 4, 6356, 1254, 52, 226170, 80508, 72308, 11, 2169, 7597, 61, 4, 923, 15, 249619, 168974, 243480, 68212, 9169, 75, 34]\n",
    "shift = np.insert(np.cumsum(emb_size_array), 0, 0)[:-1]\n",
    "test_df=pd.read_csv(\"/hps_infer/infer_test.csv\",sep=',').head(batch_szie)\n",
    "\n",
    "\n",
    "\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    dense_features = np.array([list(test_df[CONTINUOUS_COLUMNS].values.flatten())],dtype='float32')\n",
    "    input  = test_df[CATEGORICAL_COLUMNS]+shift\n",
    "    #Input format of \"KEYS\"= [keys of embedding table1, keys of embedding table2,...]\n",
    "    #Input format of \"NUMKEYS\"= [ the number of keys in embedding table1 for looking up, the number of keys in embedding table2 for looking up,...]\n",
    "    embedding_columns = np.array([list(input[emb1].values.flatten())+list(input[emb2].values.flatten())],dtype='int64')\n",
    "\n",
    "    row_ptrs = np.array([[batch_szie*2,batch_szie*26]],dtype='int32')\n",
    "\n",
    "    inputs = [\n",
    "        httpclient.InferInput(\"KEYS\", embedding_columns.shape,\n",
    "                              np_to_triton_dtype(embedding_columns.dtype)),\n",
    "        httpclient.InferInput(\"NUMKEYS\", row_ptrs.shape,\n",
    "                              np_to_triton_dtype(row_ptrs.dtype)),\n",
    "\n",
    "    ]\n",
    "\n",
    "    inputs[0].set_data_from_numpy(embedding_columns)\n",
    "    inputs[1].set_data_from_numpy(row_ptrs)\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    response = client.infer(model_name,\n",
    "                            inputs,\n",
    "                            request_id=str(1),\n",
    "                            outputs=outputs)\n",
    "\n",
    "    result = response.get_response()\n",
    "    print(result)\n",
    "    print(\"The embedding vecotor shape is(batchsize*2*embedding1_vector_size + batchsize*26*embedding2_vector_size):\")\n",
    "    print(response.as_numpy(\"OUTPUT0\").shape)\n",
    "    print(\"Prediction Result:\")\n",
    "    print(response.as_numpy(\"OUTPUT0\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3474067b",
   "metadata": {},
   "source": [
    "## 4.3 Send requests to HPS Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c575b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'model_name': 'hps_wdl', 'model_version': '1', 'parameters': {'NumSample': 10, 'DeviceID': 0}, 'outputs': [{'name': 'OUTPUT0', 'datatype': 'FP32', 'shape': [4180], 'parameters': {'binary_data_size': 16720}}]}\n",
      "The embedding vecotor shape is(batchsize*2*embedding1_vector_size + batchsize*26*embedding2_vector_size):\n",
      "(4180,)\n",
      "Prediction Result:\n",
      "[-0.05476952 -0.08410043 -0.00947467 ... -0.00037787  0.02533177\n",
      "  0.00137331]\n"
     ]
    }
   ],
   "source": [
    "!python3 /hps_infer/hps2predict.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
